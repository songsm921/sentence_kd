{
  "kd_mode": "hybrid",
  "temperature": 1.0,
  "initial_gate_value": 0.5,
  "prefix_length": 10,
  "teacher_model_name_or_path": "/mnt/cephfs/sumin/model/Llama-3.2-3B-Instruct",
  "student_model_name_or_path": "/mnt/cephfs/sumin/model/Llama-3.2-1B-Instruct",
  "from_checkpoint": null,
  "max_seq_length": 2048,
  "per_device_train_batch_size": 1,
  "per_device_eval_batch_size": 1,
  "gradient_accumulation_steps": 8,
  "learning_rate": 5e-05,
  "weight_decay": 0.01,
  "num_train_epochs": 3,
  "lr_scheduler_type": "linear",
  "warmup_steps": 500,
  "seed": 42,
  "output_dir": "./output/hybrid_prefix10",
  "logging_steps": 10,
  "save_steps": 1000,
  "save_total_limit": 3,
  "eval_steps": 500,
  "deepspeed": "ds_config.json",
  "local_rank": 0,
  "use_wandb": false,
  "wandb_project": "llama-knowledge-distillation",
  "wandb_name": null
}